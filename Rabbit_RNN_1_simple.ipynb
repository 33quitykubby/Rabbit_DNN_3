{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rabbit_RNN_1_simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/33quitykubby/Rabbit_DNN_3/blob/main/Rabbit_RNN_1_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndo0gsKs29oE"
      },
      "source": [
        "# RNN\n",
        "\n",
        "サンプルコード3_1_simple_RNN_after.ipynb  \n",
        "写経  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFawz7zCioGw"
      },
      "source": [
        "# 日本時間にする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqk7xVQXilAv",
        "outputId": "0635346d-4e4c-4aa4-c436-5a9d93a36270"
      },
      "source": [
        "  !rm /etc/localtime\n",
        "  !ln -s /usr/share/zoneinfo/Asia/Tokyo /etc/localtime\n",
        "  !date"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May  4 14:06:15 JST 2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EUDqQf0KYPQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XSgZcpT4tkC"
      },
      "source": [
        "# ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hlcGt_j4tkD"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import librosa\n",
        "\n",
        "import datetime\n",
        "\n",
        "import gc\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "from pandas import DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Kfi-5YVRYV",
        "outputId": "256f1cfe-394e-40b4-a6b1-038275154bc7"
      },
      "source": [
        "#開始時刻\n",
        "start_time = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "print(\"start_time=\",start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start_time= 2021-05-04 14:06:18.898592+09:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdzrJm_XYr17"
      },
      "source": [
        "# 乱数シードの初期化\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNUHyFvYF1_Z"
      },
      "source": [
        "import os \n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "COMMON_SEED = 0\n",
        "STANDARD_SEED = 0\n",
        "NP_SEED = 0\n",
        "TF_SEED = 0 \n",
        "\n",
        "# np.random.seed(STANDARD_SEED)\n",
        "# random.seed(NP_SEED)\n",
        "# tf.random.set_seed(TF_SEED)\n",
        "\n",
        "def seed_everything():\n",
        "    random.seed(STANDARD_SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(COMMON_SEED)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    np.random.seed(NP_SEED)\n",
        "    tf.random.set_seed(TF_SEED)\n",
        "    session_conf = tf.compat.v1.ConfigProto(\n",
        "        intra_op_parallelism_threads=1,\n",
        "        inter_op_parallelism_threads=1\n",
        "    )\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AOmh1f2uhww"
      },
      "source": [
        "#乱数シード固定\n",
        "\n",
        "seed_everything()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJCupj3PTDaz"
      },
      "source": [
        "# デバッグプリント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjg6IOY1SvJZ"
      },
      "source": [
        "DEBUG = False\n",
        "\n",
        "def debugPrint(str, debug=True):\n",
        "  if debug :\n",
        "    print(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIWl1GBrzGJA"
      },
      "source": [
        "# concatenateのテスト(RNNとは直接関係なし）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULl0XmZuw_m9",
        "outputId": "4a2e76a3-00a7-4ae7-ae22-de08fe67a626"
      },
      "source": [
        "\n",
        "a1 = np.ones((2, 3), int)\n",
        "# print(a1)\n",
        "# [[1 1 1]\n",
        "#  [1 1 1]]\n",
        "\n",
        "a2 = np.full((2, 3), 2)\n",
        "# print(a2)\n",
        "# [[2 2 2]\n",
        "#  [2 2 2]]\n",
        "\n",
        "print(np.concatenate([a1,a2],axis=0))\n",
        "print(np.concatenate([a1,a2],axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1]\n",
            " [1 1 1]\n",
            " [2 2 2]\n",
            " [2 2 2]]\n",
            "[[1 1 1 2 2 2]\n",
            " [1 1 1 2 2 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXXh5d_gKCxM"
      },
      "source": [
        "# 共通クラス"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e8hyPJMKVyM"
      },
      "source": [
        "# 共通関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqMq2ic-M2JI"
      },
      "source": [
        "## sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlIxEAKXMyti"
      },
      "source": [
        "# sigmoid\n",
        "def func_sigmoid(u):\n",
        "  return 1/(1+np.exp(-u))\n",
        "\n",
        "# sigmoid 微分\n",
        "def func_d_sigmoid(y):\n",
        "  return (1-func_sigmoid(y))*func_sigmoid(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9PEuS50Nj6_"
      },
      "source": [
        "## tanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cswhmxEcNj7B"
      },
      "source": [
        "# tanh\n",
        "def func_tanh(u):\n",
        "  return np.tanh(u)\n",
        "\n",
        "# sigmoid 微分\n",
        "def func_d_tanh(y):\n",
        "  return 1/(np.cosh(x)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIzKW7_WYhfh"
      },
      "source": [
        "## mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9c0jK9lYoGL"
      },
      "source": [
        "def func_MSE(d, y):\n",
        "  return np.mean(np.square(d - y)) / 2\n",
        "\n",
        "def func_d_MSE(d, y):\n",
        "  if type(d) == np.ndarray:\n",
        "    batch_size = d.shape[0]\n",
        "    dx = (y-d)/batch_size\n",
        "  else:\n",
        "    dx = (y-d)\n",
        "\n",
        "  return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Ke8jDeO7v-"
      },
      "source": [
        "# RNN 処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnJTqv3eP0yE"
      },
      "source": [
        "## 入力データ準備\n",
        "\n",
        "8桁の2進数を生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw5I0da-O-5A",
        "outputId": "0d438155-8b1b-4b85-9da9-182d7cd758ea"
      },
      "source": [
        "#データ準備\n",
        "#2進数の桁数\n",
        "binary_dim = 8\n",
        "\n",
        "#最大値+1\n",
        "largest_number = pow(2, binary_dim)\n",
        "print(\"largest_number=\",largest_number)\n",
        "\n",
        "#largest_numberまでの2進数を容易\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "print(\"binary=\",binary)\n",
        "print(\"binary.shape=\",binary.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "largest_number= 256\n",
            "binary= [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 1]\n",
            " [0 0 0 ... 0 1 0]\n",
            " ...\n",
            " [1 1 1 ... 1 0 1]\n",
            " [1 1 1 ... 1 1 0]\n",
            " [1 1 1 ... 1 1 1]]\n",
            "binary.shape= (256, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SP7HEOMQnC3"
      },
      "source": [
        "## RNN初期値定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6gm2vToQU-9"
      },
      "source": [
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "# iters_num = 1000 #動きを見るだけのため\n",
        "plot_interval = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIXVY09-Q1I8"
      },
      "source": [
        "#重み初期化（バイアスは簡単のために省略している)\n",
        "\n",
        "Win = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "Wout = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE4dkN5wRdqg"
      },
      "source": [
        "#勾配\n",
        "\n",
        "Win_grad = np.zeros_like(Win)\n",
        "Wout_grad = np.zeros_like(Wout)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B4mLpNPSC0L"
      },
      "source": [
        "## RNN イテレーション"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSMXWDrySEjB",
        "outputId": "844b2d10-9b33-4a9f-f136-f22c49fdba0c"
      },
      "source": [
        "for i in range(iters_num):\n",
        "\n",
        "  # a + b = d\n",
        "  a_int = np.random.randint(largest_number/2)\n",
        "  a_bin = binary[a_int] # binary_encoding\n",
        "  b_int = np.random.randint(largest_number/2)\n",
        "  b_bin = binary[b_int] # binary_encoding\n",
        "\n",
        "  # 正解データ\n",
        "  d_int = a_int + b_int\n",
        "  d_bin = binary[d_int]\n",
        "\n",
        "  debugPrint(\"a:{}/{}\".format(a_bin,a_int),DEBUG)\n",
        "  debugPrint(\"b:{}/{}\".format(b_bin,b_int),DEBUG)\n",
        "  debugPrint(\"d:{}/{}\".format(d_bin,d_int),DEBUG)\n",
        "\n",
        "  # 出力バイナリ\n",
        "  out_bin = np.zeros_like(d_bin)\n",
        "\n",
        "  # 時系列全体の誤差\n",
        "  all_loss = 0\n",
        "\n",
        "  #時系列ループ\n",
        "  for t in range(binary_dim):\n",
        "    #入力値(入力データの一番下の桁から)\n",
        "    X = np.array([a_bin [-(t+1)], b_bin[-(t+1)]]).reshape(1,-1)\n",
        "    #時刻t+1における正解データ\n",
        "    dd = np.array([d_bin[binary_dim-(t+1)]])\n",
        "\n",
        "    print(\"X=\",X)\n",
        "    print(\"X.shape=\",X.shape)\n",
        "    print(\"dd=\",dd)\n",
        "    print(\"dd.shape=\",dd.shape)\n",
        "\n",
        "    debugPrint(\"X:{}\".format(X), DEBUG)\n",
        "    debugPrint(\"dd:{}\".format(dd), DEBUG)\n",
        "    \n",
        "    # u = X*Win + z(前の時刻(t)の中間層)*W\n",
        "    u[:, t+1] = np.dot(X, Win) + np.dot(z[:,t].reshape(1,-1), W)\n",
        "    # z = 現在時刻(t+1)の中間層出力\n",
        "    z[:, t+1] = func_sigmoid(u[:, t+1])\n",
        "    # y = 前の時刻(t)の出力\n",
        "    y[:, t] = func_sigmoid(np.dot(z[:, t+1].reshape(1,-1), Wout))\n",
        "    # print(\"z[:, t+1]=\",z[:, t+1])\n",
        "    # print(\"Wout=\",Wout)\n",
        "\n",
        "    #誤差\n",
        "    loss = func_MSE(dd, y[:,t])\n",
        "\n",
        "    #δout,t =(dE/dv)= (dE/dy)・(dy/dv)\n",
        "    # y = g(z) = sigmoid(z)\n",
        "    # v = Wout・z\n",
        "    delta_out[:, t] = func_d_MSE(dd, y[:,t]) * func_d_sigmoid(y[:,t])\n",
        "\n",
        "    all_loss += loss\n",
        "\n",
        "    # print(\"y[:,t]=\",y[:,t])\n",
        "\n",
        "    out_bin[binary_dim -(t+1)] = np.round(y[:,t])\n",
        "    # out_bin[binary_dim -(t+1)] = 0\n",
        "    # a = np.round(y[:,t])\n",
        "\n",
        "    # print(\"out_bin=\",out_bin)\n",
        "    # print(\"a=\",a)\n",
        "\n",
        "    #デバッグ出力\n",
        "    debugPrint(\"y:{}\".format(y), DEBUG)\n",
        "    debugPrint(\"out_bin:{}\".format(out_bin), DEBUG)\n",
        "    debugPrint(\"loss:{}, all_loss:{}\".format(loss, all_loss), DEBUG)\n",
        "\n",
        "  # BPTT\n",
        "  for t in range(binary_dim)[::-1]:\n",
        "    X = np.array([a_bin[-(t+1)], b_bin[-(t+1)]]).reshape(1, -1)\n",
        "\n",
        "    #δt = (dE/du_t = (dE/dv)・(dv/du_t) + (dE/du_t+1)・(du_t+1/du_t)\n",
        "    #dE/du_tを中間層由来の勾配と、前の時間方向由来の勾配で加算している（ようだ）\n",
        "    delta[:,t] = (np.dot(delta[:, t+1].T, W.T) + np.dot(delta_out[:,t].T, Wout.T)) * func_d_sigmoid(u[:,t+1])\n",
        "\n",
        "    #勾配更新\n",
        "    #dE/dWout = δt zt\n",
        "    Wout_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "    # print(\"z=\",z[:,t+1])\n",
        "    # print(\"delta_out=\",delta_out[:,t])\n",
        "    # print(\"Wout_grad=\",Wout_grad)\n",
        "\n",
        "    #dE/dW = δt zt-1\n",
        "    W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "    #dE/dWin = δt Xt\n",
        "    Win_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "\n",
        "\n",
        "  #勾配適用\n",
        "  Win -= learning_rate*Win_grad\n",
        "  W -= learning_rate*W_grad\n",
        "  Wout -= learning_rate*Wout_grad\n",
        "\n",
        "  Win_grad *= 0\n",
        "  W_grad *= 0\n",
        "  Wout_grad *=0\n",
        "\n",
        "  if (i % plot_interval==0):\n",
        "    all_losses.append(all_loss)\n",
        "    print(\"iters:\"+str(i))\n",
        "    print(\"Losses:\"+str(all_loss))\n",
        "    print(\"Pred:\"+str(out_bin))\n",
        "    print(\"True:\"+str(d_bin))\n",
        "    out_int = 0\n",
        "\n",
        "    for index, x in enumerate(reversed(out_bin)):\n",
        "      out_int += x * pow(2, index)\n",
        "\n",
        "    print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "    print(\"---------------------------------------\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Losses:1.707290143715457\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "114 + 33 = 0\n",
            "---------------------------------------\n",
            "iters:100\n",
            "Losses:1.060738094110787\n",
            "Pred:[1 1 1 1 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "32 + 122 = 240\n",
            "---------------------------------------\n",
            "iters:200\n",
            "Losses:0.9895922349883179\n",
            "Pred:[1 1 0 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "35 + 71 = 203\n",
            "---------------------------------------\n",
            "iters:300\n",
            "Losses:1.1803873452700202\n",
            "Pred:[1 1 1 0 1 0 1 1]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "29 + 55 = 235\n",
            "---------------------------------------\n",
            "iters:400\n",
            "Losses:1.0950966035330738\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "94 + 87 = 128\n",
            "---------------------------------------\n",
            "iters:500\n",
            "Losses:0.8978626213091495\n",
            "Pred:[1 1 1 1 1 0 0 1]\n",
            "True:[0 0 0 1 1 0 0 0]\n",
            "9 + 15 = 249\n",
            "---------------------------------------\n",
            "iters:600\n",
            "Losses:0.8977699149626932\n",
            "Pred:[0 0 0 0 1 1 1 1]\n",
            "True:[0 0 0 0 1 1 1 0]\n",
            "9 + 5 = 15\n",
            "---------------------------------------\n",
            "iters:700\n",
            "Losses:1.0555132372595804\n",
            "Pred:[1 1 1 1 0 0 1 1]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "123 + 89 = 243\n",
            "---------------------------------------\n",
            "iters:800\n",
            "Losses:1.2493472293844012\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "25 + 76 = 255\n",
            "---------------------------------------\n",
            "iters:900\n",
            "Losses:1.1095574570812021\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "36 + 28 = 124\n",
            "---------------------------------------\n",
            "iters:1000\n",
            "Losses:0.9881373389878267\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "29 + 111 = 184\n",
            "---------------------------------------\n",
            "iters:1100\n",
            "Losses:0.9193817862983151\n",
            "Pred:[1 1 1 1 1 0 0 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "56 + 115 = 249\n",
            "---------------------------------------\n",
            "iters:1200\n",
            "Losses:1.326310405421317\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "101 + 59 = 254\n",
            "---------------------------------------\n",
            "iters:1300\n",
            "Losses:0.9881076206116023\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "126 + 101 = 223\n",
            "---------------------------------------\n",
            "iters:1400\n",
            "Losses:0.9517013969729178\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "54 + 82 = 36\n",
            "---------------------------------------\n",
            "iters:1500\n",
            "Losses:1.0403213359384724\n",
            "Pred:[0 0 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "16 + 71 = 25\n",
            "---------------------------------------\n",
            "iters:1600\n",
            "Losses:1.0799825318505087\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "118 + 77 = 187\n",
            "---------------------------------------\n",
            "iters:1700\n",
            "Losses:0.6684504551668222\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "12 + 64 = 0\n",
            "---------------------------------------\n",
            "iters:1800\n",
            "Losses:0.7327385861267903\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "83 + 39 = 88\n",
            "---------------------------------------\n",
            "iters:1900\n",
            "Losses:0.7100703308867574\n",
            "Pred:[1 1 0 1 1 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "98 + 111 = 217\n",
            "---------------------------------------\n",
            "iters:2000\n",
            "Losses:0.5643249470743199\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "50 + 105 = 155\n",
            "---------------------------------------\n",
            "iters:2100\n",
            "Losses:0.5639001366988352\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "0 + 75 = 75\n",
            "---------------------------------------\n",
            "iters:2200\n",
            "Losses:0.7667194791494157\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "8 + 39 = 41\n",
            "---------------------------------------\n",
            "iters:2300\n",
            "Losses:0.6598748391637124\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "62 + 29 = 123\n",
            "---------------------------------------\n",
            "iters:2400\n",
            "Losses:0.7450140562236385\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "40 + 24 = 32\n",
            "---------------------------------------\n",
            "iters:2500\n",
            "Losses:0.36248838426268454\n",
            "Pred:[0 0 0 1 1 1 1 0]\n",
            "True:[0 0 0 1 1 1 1 0]\n",
            "7 + 23 = 30\n",
            "---------------------------------------\n",
            "iters:2600\n",
            "Losses:0.9469456637013689\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "45 + 52 = 75\n",
            "---------------------------------------\n",
            "iters:2700\n",
            "Losses:0.4612927834826239\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "6 + 126 = 128\n",
            "---------------------------------------\n",
            "iters:2800\n",
            "Losses:0.4865434196818608\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "13 + 58 = 69\n",
            "---------------------------------------\n",
            "iters:2900\n",
            "Losses:0.17303489045486684\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "18 + 34 = 52\n",
            "---------------------------------------\n",
            "iters:3000\n",
            "Losses:0.3111832110896146\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "38 + 86 = 124\n",
            "---------------------------------------\n",
            "iters:3100\n",
            "Losses:0.25236413624306997\n",
            "Pred:[1 1 1 0 1 0 0 0]\n",
            "True:[1 1 1 0 1 0 0 0]\n",
            "114 + 118 = 232\n",
            "---------------------------------------\n",
            "iters:3200\n",
            "Losses:0.6784264694683986\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "105 + 70 = 185\n",
            "---------------------------------------\n",
            "iters:3300\n",
            "Losses:0.38155602813302\n",
            "Pred:[1 1 0 0 1 1 1 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "79 + 127 = 206\n",
            "---------------------------------------\n",
            "iters:3400\n",
            "Losses:0.17289310852782394\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "61 + 57 = 118\n",
            "---------------------------------------\n",
            "iters:3500\n",
            "Losses:0.22704962212269034\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "9 + 100 = 111\n",
            "---------------------------------------\n",
            "iters:3600\n",
            "Losses:0.23242624468195183\n",
            "Pred:[1 1 0 1 0 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "89 + 125 = 214\n",
            "---------------------------------------\n",
            "iters:3700\n",
            "Losses:0.5334150849094413\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "111 + 65 = 172\n",
            "---------------------------------------\n",
            "iters:3800\n",
            "Losses:0.05870140511756815\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "68 + 110 = 178\n",
            "---------------------------------------\n",
            "iters:3900\n",
            "Losses:0.23380152702374343\n",
            "Pred:[0 0 1 1 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "22 + 27 = 49\n",
            "---------------------------------------\n",
            "iters:4000\n",
            "Losses:0.21483161086605204\n",
            "Pred:[1 1 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "121 + 35 = 220\n",
            "---------------------------------------\n",
            "iters:4100\n",
            "Losses:0.1990299799783953\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "26 + 105 = 131\n",
            "---------------------------------------\n",
            "iters:4200\n",
            "Losses:0.15034613592100832\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "92 + 70 = 162\n",
            "---------------------------------------\n",
            "iters:4300\n",
            "Losses:0.06311569537175164\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "120 + 101 = 221\n",
            "---------------------------------------\n",
            "iters:4400\n",
            "Losses:0.16763110858172267\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "85 + 67 = 156\n",
            "---------------------------------------\n",
            "iters:4500\n",
            "Losses:0.28056834493014515\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "126 + 9 = 135\n",
            "---------------------------------------\n",
            "iters:4600\n",
            "Losses:0.13564618204086362\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "23 + 76 = 99\n",
            "---------------------------------------\n",
            "iters:4700\n",
            "Losses:0.03384061076531421\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "25 + 93 = 118\n",
            "---------------------------------------\n",
            "iters:4800\n",
            "Losses:0.021587450166081837\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "2 + 120 = 122\n",
            "---------------------------------------\n",
            "iters:4900\n",
            "Losses:0.010500652277448709\n",
            "Pred:[0 0 0 1 1 0 0 1]\n",
            "True:[0 0 0 1 1 0 0 1]\n",
            "8 + 17 = 25\n",
            "---------------------------------------\n",
            "iters:5000\n",
            "Losses:0.11810604740210288\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "71 + 81 = 152\n",
            "---------------------------------------\n",
            "iters:5100\n",
            "Losses:0.022485040290248715\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "71 + 36 = 107\n",
            "---------------------------------------\n",
            "iters:5200\n",
            "Losses:0.0867503470112707\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "127 + 30 = 157\n",
            "---------------------------------------\n",
            "iters:5300\n",
            "Losses:0.03154550245480353\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "47 + 123 = 170\n",
            "---------------------------------------\n",
            "iters:5400\n",
            "Losses:0.024909185535842912\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "10 + 87 = 97\n",
            "---------------------------------------\n",
            "iters:5500\n",
            "Losses:0.03128703478555425\n",
            "Pred:[1 1 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "88 + 107 = 195\n",
            "---------------------------------------\n",
            "iters:5600\n",
            "Losses:0.02919664890693719\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "43 + 57 = 100\n",
            "---------------------------------------\n",
            "iters:5700\n",
            "Losses:0.014942122784306991\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "51 + 5 = 56\n",
            "---------------------------------------\n",
            "iters:5800\n",
            "Losses:0.018076703002805873\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "103 + 39 = 142\n",
            "---------------------------------------\n",
            "iters:5900\n",
            "Losses:0.02251642092997442\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "51 + 109 = 160\n",
            "---------------------------------------\n",
            "iters:6000\n",
            "Losses:0.023859237120863307\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "91 + 108 = 199\n",
            "---------------------------------------\n",
            "iters:6100\n",
            "Losses:0.011803168039390403\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "68 + 40 = 108\n",
            "---------------------------------------\n",
            "iters:6200\n",
            "Losses:0.004586437384789273\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "25 + 29 = 54\n",
            "---------------------------------------\n",
            "iters:6300\n",
            "Losses:0.012997572381594035\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "112 + 23 = 135\n",
            "---------------------------------------\n",
            "iters:6400\n",
            "Losses:0.012221056690492156\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "76 + 104 = 180\n",
            "---------------------------------------\n",
            "iters:6500\n",
            "Losses:0.015622574828303034\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "87 + 48 = 135\n",
            "---------------------------------------\n",
            "iters:6600\n",
            "Losses:0.0018901310496388882\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "73 + 27 = 100\n",
            "---------------------------------------\n",
            "iters:6700\n",
            "Losses:0.009333832185131216\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "94 + 69 = 163\n",
            "---------------------------------------\n",
            "iters:6800\n",
            "Losses:0.003906180893648057\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "79 + 111 = 190\n",
            "---------------------------------------\n",
            "iters:6900\n",
            "Losses:0.007220129786776308\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "106 + 65 = 171\n",
            "---------------------------------------\n",
            "iters:7000\n",
            "Losses:0.0030958693707486148\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "13 + 24 = 37\n",
            "---------------------------------------\n",
            "iters:7100\n",
            "Losses:0.0031368797764500353\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "68 + 105 = 173\n",
            "---------------------------------------\n",
            "iters:7200\n",
            "Losses:0.010906233921588116\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "94 + 3 = 97\n",
            "---------------------------------------\n",
            "iters:7300\n",
            "Losses:0.014204591822884608\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "47 + 89 = 136\n",
            "---------------------------------------\n",
            "iters:7400\n",
            "Losses:0.008347127199501715\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "106 + 104 = 210\n",
            "---------------------------------------\n",
            "iters:7500\n",
            "Losses:0.006463013545352231\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "0 + 46 = 46\n",
            "---------------------------------------\n",
            "iters:7600\n",
            "Losses:0.006086633767248353\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "74 + 84 = 158\n",
            "---------------------------------------\n",
            "iters:7700\n",
            "Losses:0.009952177543089724\n",
            "Pred:[1 1 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "93 + 99 = 192\n",
            "---------------------------------------\n",
            "iters:7800\n",
            "Losses:0.005000050500846169\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "83 + 49 = 132\n",
            "---------------------------------------\n",
            "iters:7900\n",
            "Losses:0.006769036504134604\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "102 + 37 = 139\n",
            "---------------------------------------\n",
            "iters:8000\n",
            "Losses:0.0036642475615400716\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "47 + 32 = 79\n",
            "---------------------------------------\n",
            "iters:8100\n",
            "Losses:0.0019526426315987979\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "39 + 75 = 114\n",
            "---------------------------------------\n",
            "iters:8200\n",
            "Losses:0.005248066762627508\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "72 + 8 = 80\n",
            "---------------------------------------\n",
            "iters:8300\n",
            "Losses:0.0024724073785905233\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "36 + 81 = 117\n",
            "---------------------------------------\n",
            "iters:8400\n",
            "Losses:0.0016527838279839636\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "117 + 87 = 204\n",
            "---------------------------------------\n",
            "iters:8500\n",
            "Losses:0.0017928999515504109\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "47 + 119 = 166\n",
            "---------------------------------------\n",
            "iters:8600\n",
            "Losses:0.005818374356555952\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "6 + 60 = 66\n",
            "---------------------------------------\n",
            "iters:8700\n",
            "Losses:0.0010868966366949365\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "109 + 49 = 158\n",
            "---------------------------------------\n",
            "iters:8800\n",
            "Losses:0.0018507746993968355\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "32 + 33 = 65\n",
            "---------------------------------------\n",
            "iters:8900\n",
            "Losses:0.0037587917113469102\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "2 + 50 = 52\n",
            "---------------------------------------\n",
            "iters:9000\n",
            "Losses:0.00475704941152523\n",
            "Pred:[0 0 0 1 1 0 0 0]\n",
            "True:[0 0 0 1 1 0 0 0]\n",
            "12 + 12 = 24\n",
            "---------------------------------------\n",
            "iters:9100\n",
            "Losses:0.0015585240363073178\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "81 + 72 = 153\n",
            "---------------------------------------\n",
            "iters:9200\n",
            "Losses:0.0038811864267783436\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "76 + 74 = 150\n",
            "---------------------------------------\n",
            "iters:9300\n",
            "Losses:0.0017272412294955584\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "7 + 113 = 120\n",
            "---------------------------------------\n",
            "iters:9400\n",
            "Losses:0.001373913494399491\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "39 + 106 = 145\n",
            "---------------------------------------\n",
            "iters:9500\n",
            "Losses:0.0008719704904651608\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "23 + 35 = 58\n",
            "---------------------------------------\n",
            "iters:9600\n",
            "Losses:0.003295317900079471\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "76 + 92 = 168\n",
            "---------------------------------------\n",
            "iters:9700\n",
            "Losses:0.001734389019146042\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "115 + 40 = 155\n",
            "---------------------------------------\n",
            "iters:9800\n",
            "Losses:0.0018376128323502466\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "110 + 79 = 189\n",
            "---------------------------------------\n",
            "iters:9900\n",
            "Losses:0.002992014427310139\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "38 + 106 = 144\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x85n3tbEHIJx"
      },
      "source": [
        "\n",
        "# `グラフ表示`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5GPEJnN_Ov5",
        "outputId": "88afa06a-7afa-4f46-9b46-e8f2b2bf1f3d"
      },
      "source": [
        "print(all_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.707290143715457, 1.060738094110787, 0.9895922349883179, 1.1803873452700202, 1.0950966035330738, 0.8978626213091495, 0.8977699149626932, 1.0555132372595804, 1.2493472293844012, 1.1095574570812021, 0.9881373389878267, 0.9193817862983151, 1.326310405421317, 0.9881076206116023, 0.9517013969729178, 1.0403213359384724, 1.0799825318505087, 0.6684504551668222, 0.7327385861267903, 0.7100703308867574, 0.5643249470743199, 0.5639001366988352, 0.7667194791494157, 0.6598748391637124, 0.7450140562236385, 0.36248838426268454, 0.9469456637013689, 0.4612927834826239, 0.4865434196818608, 0.17303489045486684, 0.3111832110896146, 0.25236413624306997, 0.6784264694683986, 0.38155602813302, 0.17289310852782394, 0.22704962212269034, 0.23242624468195183, 0.5334150849094413, 0.05870140511756815, 0.23380152702374343, 0.21483161086605204, 0.1990299799783953, 0.15034613592100832, 0.06311569537175164, 0.16763110858172267, 0.28056834493014515, 0.13564618204086362, 0.03384061076531421, 0.021587450166081837, 0.010500652277448709, 0.11810604740210288, 0.022485040290248715, 0.0867503470112707, 0.03154550245480353, 0.024909185535842912, 0.03128703478555425, 0.02919664890693719, 0.014942122784306991, 0.018076703002805873, 0.02251642092997442, 0.023859237120863307, 0.011803168039390403, 0.004586437384789273, 0.012997572381594035, 0.012221056690492156, 0.015622574828303034, 0.0018901310496388882, 0.009333832185131216, 0.003906180893648057, 0.007220129786776308, 0.0030958693707486148, 0.0031368797764500353, 0.010906233921588116, 0.014204591822884608, 0.008347127199501715, 0.006463013545352231, 0.006086633767248353, 0.009952177543089724, 0.005000050500846169, 0.006769036504134604, 0.0036642475615400716, 0.0019526426315987979, 0.005248066762627508, 0.0024724073785905233, 0.0016527838279839636, 0.0017928999515504109, 0.005818374356555952, 0.0010868966366949365, 0.0018507746993968355, 0.0037587917113469102, 0.00475704941152523, 0.0015585240363073178, 0.0038811864267783436, 0.0017272412294955584, 0.001373913494399491, 0.0008719704904651608, 0.003295317900079471, 0.001734389019146042, 0.0018376128323502466, 0.002992014427310139]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyhXc8FJueE0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2b6f8bf8-9a99-41d7-f08b-0dc000fd254c"
      },
      "source": [
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8AH400idpTk"
      },
      "source": [
        "# 終わり"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdBIu4za5umf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e291e8-fef7-4a68-a7b8-b44054865964"
      },
      "source": [
        "#終了時刻\n",
        "finish_time = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "print(\"finish_time=\",finish_time)\n",
        "print(\"total_time=\",finish_time-start_time)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish_time= 2021-05-04 10:31:48.803293+09:00\n",
            "total_time= 0:00:36.787577\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}